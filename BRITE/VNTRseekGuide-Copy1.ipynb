{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running VNTRseek on any dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "Tools used: \n",
    "`samtools` and `bedtools`\n",
    "  \n",
    "Need:  \n",
    "1. wgs dataset (sample genome)\n",
    "    - in either FASTQ, BAM, or CRAM formats\n",
    "2. GRCh38 reference genome\n",
    "    - without alts (chr1-22,XY,M) on SCC: /project/vntrseek/share/GRCh38/GRCh38.fa\n",
    "    - with alts (correct if using data from 1000 Genomes project)\n",
    "        - [reference genome file](https://github.com/igsr/1000Genomes_data_indexes/blob/master/data_collections/gambian_genome_variation_project/README_gambian_genome_variation_project.md)   \n",
    "            \\*must be the one used to map original FASTQ files\n",
    "            - download via\n",
    "                `lftp`\n",
    "                `pget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/GRCh38_reference_genome/GRCh38_full_analysis_set_plus_decoy_hla.fa` \n",
    "\n",
    "To load:   \n",
    "`module load samtools`  \n",
    "`module load bedtools`\n",
    "\n",
    "NOTE: any terminal commands starred\\* means that they should go inside a script\n",
    " - Script how-to at end of guide\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Make a new directory in /projectnb/vntrseek for yourself (ex: sfiller)\n",
    " - Within it create a folder with title of wgs data you are mapping (ex: NYGC_na18545)\n",
    " - command into NYGC_na18545 directory\n",
    " - type `lftp`\n",
    " - to download files:\n",
    "     - FASTQ \n",
    "         - `pget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR323/007/ERR3239357/ERR3239357_1.fastq.gz`\n",
    "         - `pget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR323/007/ERR3239357/ERR3239357_2.fastq.gz`\n",
    "     - CRAM\n",
    "         - `pget ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR323/ERR3239357/NA18545.final.cram`\n",
    " - Now unzip each file\n",
    "     - `gunzip file.name`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VNTRseek accepts 2 file types:\n",
    " 1. FASTQ\n",
    " 2. BAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will input datasets be ...  \n",
    " a) **complete** (unfiltered)  \n",
    " b) **restricted** (filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A)** If running complete dataset (not filtering): \n",
    " - use FASTQ\n",
    "     - place fastq files (2) in their own directory\n",
    " - use BAM \n",
    "     - place BAM file in its own directory\n",
    "     - index the BAM file so it is also in the same directory\n",
    "         - `samtools index file_name.bam`\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B)** If running a restricted dataset (filtered) - need to get into BAM format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - if starting from FASTQ\n",
    "    1. Map 2 paired-end fastq files to reference genome - output: BAM file\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOW: \n",
    "________________________\n",
    "- Copy map_one_file.sh script from /projectnb/vntrseek/scripts/bwa_alignment/map_one_file.sh into your personal directory NYGC_na18545, modify\n",
    "    - add flags:   \n",
    "      `set e` stops the execution of the script if an error occurs  \n",
    "      `#$ -P vntrseek` to denote which project and to use that project's specific resources  \n",
    "      `-j y` to join output and error stream files into one   \n",
    "      `#$ -m bea` to send an email when job begins/ends/aborts  \n",
    "      `#$ -M my@email.com` overwrite default email and send to YOUR email included  \n",
    "      `-l h_rt=200:00:00`  had to set time limit to longer than 100 hours - takes a while  \n",
    "      `-pe omp 8` request number of threads  \n",
    "    - comment out the module load samtools and module load bwa (were causing errors)    \n",
    "- In NYGC_na18545 directory, `module load samtools` and `module load bwa`  \n",
    "- Then submit job:  \n",
    "     - `qsub -N na18545 -o na18545.log map_one_file.sh /projectnb/vntrseek/sfiller/NYGC_na18545/ERR3239357_1.fastq /projectnb/vntrseek/sfiller/NYGC_na18545/ERR3239357_2.fastq na18545 8`  \n",
    "     \n",
    "         `-N` job name  \n",
    "         `-o` output of job in following file name     \n",
    "         `map_one_file.sh` script used, followed by arguments for that script  \n",
    "             - arg 1: /path/to/read1.fq  \n",
    "             - arg 2:  /path/to/read2.fq  \n",
    "             - arg 3: name_of_bam_file  \n",
    "             - arg 4: number of processors to use\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if starting from CRAM \n",
    "    1. convert CRAM to BAM:     \n",
    "        \\*script needed\\*  `projectnb/vntrseek/sfiller/scripts/cram_to_bam.sh`  \n",
    "        \n",
    "        `samtools view -b  -T GRCh38_full_analysis_set_plus_decoy_hla.fa -o NA18545.final.bam NA18545.final.cram`  \n",
    "        - `-b` for bam output\n",
    "        - `-o` to create an output file \n",
    "        - `-T` for reference file\n",
    "        - first arg: [reference genome file](https://github.com/igsr/1000Genomes_data_indexes/blob/master/data_collections/gambian_genome_variation_project/README_gambian_genome_variation_project.md)   \n",
    "            \\*must be the one used to map original FASTQ files\n",
    "            - download via\n",
    "                `lftp`\n",
    "                `pget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/GRCh38_reference_genome/GRCh38_full_analysis_set_plus_decoy_hla.fa`  \n",
    "        - second arg: name of output bam (will be placed in current directory)\n",
    "        - third arg: name of input cram (must exist)  \n",
    "          \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK if number of reads are same between FASTQ files and BAM files: \n",
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Number of reads in fastq file    \n",
    "     `wc -l practice_na18545/ERR3239357_1.fastq`  \n",
    "     Output: 1579052668\n",
    "       \n",
    "     Output is number of lines. Four lines per read in a fastq file, but there are also 2 files (paired reads), so *2/4 the output, or just divide by two:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789526334.0\n"
     ]
    }
   ],
   "source": [
    "reads = 1579052668/2\n",
    "print(reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Number of reads in bam file  \n",
    "   \n",
    " Use `samtools view -c` options - give you number of ALIGNMENTS (can be larger than the actual number of reads)  \n",
    "   \n",
    "> To include only reads with certain bitwise flags - add up the bit values of the flags you want to INCLUDE:  \n",
    "            `samtools view -c -f <bitValue> file.bam`  \n",
    "              \n",
    " > To exclude reads with certain bitwise flags - add up bit values of the flags you want to EXCLUDE:  \n",
    "            `samtools view -c -F <bitValue> file.bam`\n",
    "  \n",
    "I want to exclude reads that were secondary alignments (256) *AND* any supplementary reads (2048) (in order to get my total number of distinct reads)  \n",
    "256+2048 = 2034 (leaves only primary alignments or unmapped reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samtools view -c -F 256 na18545.bam #same output when using bam made from fastq files (bwa_bam)\n",
    "samtools view -c -F 2034 na18545.bam #same as above for bwa_bam, different for db_bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: 789526334  \n",
    "  \n",
    "Both numbers record the same number of reads, move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using a restricted read dataset (if not skip to \"Run VNTRseek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use samtools and bedtools to extract primary alignment reads that map with overlap to TR regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract primary reads with Samtools from bam file and redirect into new bam file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools view -b -F 2038 na18545.bam > primary_na18545.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `-F 2038` excludes:   \n",
    "  4 - unmapped reads   \n",
    "  256 -secondary alignments   \n",
    "  2048-supplementary alignments (necessary for BAM that used GRCh38 with alts)  \n",
    "- `-b` output is in BAM format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Take only those primary reads that overlap with TR loci using Bedtools\\*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bedtools Intersect process: compare A line by line to B, to see if any reads from A overlap with regions from B, if there are, return all overlaps of A with B only once, output into a bam file\n",
    "  \n",
    "[Bedtools intersect](https://bedtools.readthedocs.io/en/latest/content/tools/intersect.html)  \n",
    "`bedtools intersect -a A.bed -b B.bed [options]`  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I created `extract_overlaps.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/bin/bash  \n",
    "\n",
    "#$ -P vntrseek  \n",
    "#$ -j y  \n",
    "#$ -l h_rt=100:00:00  \n",
    "#$ -pe omp 8  \n",
    "#$ -V  \n",
    "#$ -m e  \n",
    "#$ -M sfiller@friars.providence.edu  \n",
    "\n",
    "module load samtools  \n",
    "module load bedtools\n",
    "\n",
    "# first parameter is A file, bam file\n",
    "# second parameter is B file, bed file\n",
    "# third parameter is output file\n",
    "\n",
    "bedtools intersect -u -abam $1 -b $2 > $3    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \\$1 is A file, use `abam` for bam file input\n",
    "    - A file  - larger file (loaded a line at a time)\n",
    "- \\$2 is B file, smaller file (loaded to memory) - TR ref set BED file\n",
    "- `-u` Write original A entry once if any overlaps found in B. In other words, just report the fact at least one overlap was found in B.  \n",
    " \\*do NOT use -ubam (truncates the output bam file)\n",
    "- \\$3 output file name (BAM output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must format bed file containing TR regions, start with TR_Human_Refset_228486.bed:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure 4 column (original) bed is tab delimited: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat TR_Human_Refset_228486.bed| perl -lane 'print \"$F[0]\\t$F[1]\\t$F[2]\\t$F[3]\"' > TabDL\n",
    "M_TR_Human_Refset_228486.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Need to comment out header from TabDLM file (did via text editor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Then compare with bedtools intersect to extract overlaps using a script, extract_overlaps.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run script via submitting a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsub -N extractOverlaps /projectnb/vntrseek/sfiller/scripts/extract_overlaps.sh primary_na18545.bam TabDLM_TR_Refset.bed TR_overlaps_primaryreads_na18545.bam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VARIATIONS of restricted read dataset\n",
    "1. Add unmapped reads\n",
    "2. Add unmapped reads + primary alignments mapping to alternate chromosome regions  \n",
    "    - can only do for BAM converted from db CRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **FIRST VARIATION**: Use samtools to extract unmapped reads and add them to primary TR overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get unmapped reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools view -b -f 4 na18545.bam > unmapped.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `-b` for bam output\n",
    " - `-f 4`to include only reads that are unmapped "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort both the unmapped reads bam + primary reads that overlap TRs bam files (must do prior to merging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Use samtools sort\\*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools sort ex.bam -o ex.sorted.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Use `sortbam.sh` script  \n",
    "     - takes one argument: full path of file to sort, must exclude .bam ending  \n",
    "     - creates an output file with original name with .sorted.bam ending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both sorted bam files using samtools merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools merge primaryoverlaps_unmapped.bam TR_overlaps_primaryreads_na18545.sorted.bam unmapped.sorted.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First arg: output name  \n",
    "Second arg: first sorted file  \n",
    "Third arg: second sorted file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **SECOND VARIATION**: extract and add reads overlapping with alt chromosomes to unmapped reads and primary TR overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* Only possible for bam converted from CRAM because it was mapped using reference genome with alt chromosomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACT primary reads that mapped to alternate chromosomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Use bedtools intersect method - to extract only reads that aligned to alternative chromosomes(and any other parts of the reference genome that are not contained in the GRCh38.fa reference)\n",
    "     - Take index file for GRCh38 with alts reference genome and take only alternate chromosomes (everything after line 25) and turn into bed file (take only first and second columns - chr name and chr length, add column of zeroes in between as start of each chromosome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk 'FNR>25 {print $1 \"\\t0\\t\" $2}' GRCh38_full_analysis_set_plus_decoy_hla.fa.fai>alt_chr_intervals.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Now use this BED file with bedtools intersect to extract only primary reads that overlap with alt chr regions - output should be a bam of all these\n",
    "     - use extract_overlaps.sh scripts and submit a job (from /projectnb/vntrseek/sfiller directory)\n",
    "        - \\$1 is BAM containing primary reads\n",
    "        - \\$2 is BED containing alt chr regions\n",
    "        - \\$3 path of output file with output file name (BAM output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsub -N extractOverlaps /projectnb/vntrseek/sfiller/scripts/extract_overlaps.sh /projectnb/vntrseek/sfiller/snake_workflow/primary_reads/NA18545.final.bam alt_chr_intervals.bed /projectnb/vntrseek/sfiller/snake_workflow/primary_reads/altchr_overlaps_NA18545.final.bam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow steps in Variation 1 to sort output BAM then merge this file (containing primary reads overlapping with alt chr regions) with the bam file containing primary reads overlapping with TR regions and unmapped reads (primary_TR_overlaps+unmapped reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organization of files** / Snakemake method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also use [Snakemake](https://snakemake.readthedocs.io/en/stable/tutorial/short.html) to streamline efforts\n",
    " - I used to go from original BAM > primary reads> sort> merge with unmapped reads\n",
    " - create a Snakefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Snakemake requires folders for each step (see /projectnb/sfiller/NYGC_HG00096 for a concise example)\n",
    " - folders must be thoughtfully organized ^, file name stays the same, ex: NA18545.bam  \n",
    "\n",
    "If not using Snakemake organization method\n",
    " - files should be thoughtfully named"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run VNTRseek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running FASTQ files make sure that both files are together in a directory (nothing else in directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running BAM file, need to index before, store BAM and BAM index files together in a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Use `inxbam.sh` script to index   \n",
    "     - $1 need to type full path of file to index including .bam ending  \n",
    "     - uses `samtools index` command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using restricted read datasets, run all three variations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. primary reads overlapping with TR regions (primary_TR_overlaps)\n",
    "2. primary_TR_overlaps + unmapped\n",
    "3. primary_TR_overlaps + unmapped + primar_altchr_overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run VNTRseek by submitting a job, see Assignment 3 notebook for further explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsub -N nameOfJob vntr.v10.sh directoryNAMEofFiles startStep readLength\n",
    "#qsub -N primaryTRoverlapsVNTR vntr.v10.sh primaryoverlaps_VNTRtest 0 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First parameter after vntr.v10.sh is the directory containing the file(s) to be run and where output will go\n",
    "- Second parameter is step of VNTRseek you want to start on\n",
    "- Third parameter is length of each read in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record RUN Stats in spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After receiving email results of job completion need to record all stats (especially CPU time and wallclock time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `run_comparison_results.xlsx` (on github) as outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\\* look at Runtimes.xlsx format if using multiple runs of each kind of restricted read dataset (I used this file only to average the run times in my limited analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare output vcf files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also record numreads, numreadTRs, numVNTRs, numTRsWithSupport on output `.span2.vcf` files\n",
    " - \\* .span2.vcf files contain only VNTRs found\n",
    " - \\* allwithsupport.vcf files contain all TRs and VNTRs found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `comparevcf.py script` (on github) to compare vntrs found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How to Use*  \n",
    " - Use a text editor/IDE/notebook (I used VSCode)   \n",
    " - Once in the editor, connect to the remote server/SSH using BU login and PW  \n",
    " - Use anaconda `module load miniconda`\n",
    " - Create an environment using anaconda, `conda create --name vcfpy python=3`    \n",
    "     - \\*Called my environment 'vcfpy' (not to be confused with the library)  \n",
    " - Now activate the environment `conda activate vcfpy`  \n",
    " - Install libraries needed  \n",
    "    - `pip install vcfpy`\n",
    "    - `pip install pysam`\n",
    " - After setting up the environment (above), **regularly load via**:   \n",
    "     - `module load miniconda`\n",
    "     - `conda activate vcfpy`\n",
    "     - To run script\n",
    "         1. Make sure in the directory of the script\n",
    "         2. Type python version you would like to use, the script name, then the complete paths to the two vcf files you would like to compare (make sure to use .span2.vcf files to compare VNTRs only)  \n",
    "           `python3 comparevcf.py vcf/path/one vcf/path/two`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record differences in run_comparison_results.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run PlotVNTRresults.ipynb (github) to visualize all results found, save spreadsheet as .csv file (in same directory as the notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIONAL: Move resulting .db file from each run of VNTRseek to orca (to view in VNTRview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First gzip each db file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip file.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then secure copy (scp) the file over to the orca server, will be prompted for password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp file.db.gz sfiller@orca.bu.edu:/home/sfiller/(fileName optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once .db.gz file is processed and ready to view on VNTRview, can delete copy in orca directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once viewable on VNTRview, go to export, right click VCF ALL VNTRS and copy link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget <copied link> #to download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view file and check num_VNTRS found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file.name: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!more file.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QSUB stats:  \n",
    "- Wallclock time: difference between end time and start time  \n",
    "- CPU: cpu time usage in seconds (hours:minutes:seconds)  \n",
    "- maxvmem: the maximum virtual memory (size in bytes) that has been used during the CPU runtime  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to write a bash script - submit to queue as a noninteractive batch job via `qsub`\n",
    "`#!/bin/bash` called the shebang   \n",
    "`#$ -P vntrseek` which project's resources you will be using  \n",
    "`#$ -j y`  j for join error and output stream files into one, y for yes  \n",
    "`#$ -l h_rt=100:00:00`  time limit  \n",
    "`#$ -pe omp 8` number of processors to use   \n",
    "`#$ -V` all current environment variables should be exported to the batch job  \n",
    "`#$ -m bea` instances when you want to be emailed: Beginning, End, or Abort  \n",
    "`#$ -M desired@email.com` email to send job status to   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*Useful [GUIDE](https://www.bu.edu/tech/files/2020/01/2020_spr-Tutorial-Intermediate-Usage-of-Shared-Compute-Cluster-SCC.pdf) for submitting jobs through SCC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
